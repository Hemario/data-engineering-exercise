{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation criteria\r\n",
    "\r\n",
    "The goal of this assignment is to get a view on your hands-on \"data engineering\" skills.  \r\n",
    "At our company, our data scientists and engineers collaborate on projects.  \r\n",
    "Your main focus will be creating performant & robust data flows.  \r\n",
    "For a take-home-assignment, we cannot grant you access to our infrastructure.  \r\n",
    "The assignement below measures your proficiency in general programming, data science & engineering tasks using python.  \r\n",
    "Completion should not take more than half a day.\r\n",
    "\r\n",
    "**We expect you to be proficient in:**\r\n",
    " * SQL queries (Sybase IQ system)\r\n",
    " * ETL flows (In collaboration with existing teams)\r\n",
    " * General python to glue it all together\r\n",
    " * Python data science ecosystem (Pandas + SKlearn)\r\n",
    " \r\n",
    "**In this exercise we expect you to demonstrate your ability to / knowledge of:**\r\n",
    " * Building a data science runtime\r\n",
    " * PEP8 / Google python styleguide\r\n",
    " * Efficiently getting the job done\r\n",
    " * Choose meaningfull names for variables & functions\r\n",
    " * Writing maintainable code (yes, you might need to document some steps)\r\n",
    " * Help a data scientist present interactive results.\r\n",
    " * Offer predictions via REST api"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setting-up a data science workspace\r\n",
    "\r\n",
    "We allow you full freedom in setting up a data science runtime.  \r\n",
    "The main objective is having a runtime where you can run this notebook and the code you will develop.  \r\n",
    "You can choose for a local setup on your pc, or even a cloud setup if you're up for it.   \r\n",
    "\r\n",
    "**In your environment, you will need things for:**\r\n",
    " * https request\r\n",
    " * python3 (not python2 !!)\r\n",
    " * (geo)pandas\r\n",
    " * interactive maps (e.g. folium, altair, ...)\r\n",
    " * REST apis\r\n",
    " \r\n",
    "**Deliverables we expect**:\r\n",
    " * notebook with the completed assignment\r\n",
    " * list of packages for your runtime (e.g. yml or txt file)\r\n",
    " * evidence of a working API endpoint"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We would like you to put all your import statements here, together in 1 place.  \r\n",
    "Before submitting, please make sure you remove any unused imports :-)  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import urllib.request\r\n",
    "import json\r\n",
    "import unittest\r\n",
    "from joblib import load\r\n",
    "from math import radians, cos, sin, asin, sqrt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data ingestion exercises\r\n",
    "\r\n",
    "## Getting store location data from an API"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Goal:** Obtain a pandas dataframe  \r\n",
    "**Hint:** You will need to normalise/flatten the json, because it contains multiple levels  \r\n",
    "**API call:** https://ecgplacesmw.colruytgroup.com/ecgplacesmw/v3/nl/places/filter/clp-places  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_clp_places(url):\r\n",
    "    with urllib.request.urlopen(url) as req:\r\n",
    "        data = json.loads(req.read().decode())\r\n",
    "    df = pd.json_normalize(data)\r\n",
    "    return df\r\n",
    "\r\n",
    "df_clp = get_clp_places(\"https://ecgplacesmw.colruytgroup.com/ecgplacesmw/v3/nl/places/filter/clp-places\")\r\n",
    "df_clp.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Quality checks\r\n",
    "\r\n",
    "We would like you to add several checks on this data based on these constraints:  \r\n",
    " * records > 200\r\n",
    " * latitude between 49 and 52\r\n",
    " * longitude between 2 and 7\r\n",
    " \r\n",
    "We dont want you to create a full blown test suite here, we're just gonna use 'asserts' from unittest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tc = unittest.TestCase('__init__')\r\n",
    "# records > 200\r\n",
    "tc.assertGreater(len(df_clp.index), 200, \"There should be more than 200 records\")\r\n",
    "# latitude between 49 and 52\r\n",
    "tc.assertTrue(\r\n",
    "    (df_clp[\"geoCoordinates.latitude\"].min() >= 49) & (df_clp[\"geoCoordinates.latitude\"].max() <= 52), \r\n",
    "    \"All stores should have a latitude between 49 and 52\"\r\n",
    ")\r\n",
    "# longitude between 2 and 7\r\n",
    "tc.assertTrue(\r\n",
    "    (df_clp[\"geoCoordinates.longitude\"].min() >= 2) & (df_clp[\"geoCoordinates.longitude\"].max() <= 7), \r\n",
    "    \"All stores should have a longitude between 2 and 7\"\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature creation\r\n",
    "\r\n",
    "Create a new column \"antwerpen\" which is 1 for all stores in Antwerpen (province) and 0 for all others "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_clp[\"antwerpen\"] = np.where(df_clp[\"address.postalcode\"].astype(int).between(2000, 2999), 1, 0)\r\n",
    "df_clp[\"antwerpen\"].value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predict used car value\r\n",
    "\r\n",
    "A datascientist in our team made a basic model to predict car prices.  \r\n",
    "The model was saved to disk ('lgbr_cars.model') using joblib's dump fuctionality.  \r\n",
    "Documentation states the model is a LightGBM Regressor, trained using the sk-learn api.  \r\n",
    "\r\n",
    "**As engineer, your task it to expose this model as REST-api.** \r\n",
    "\r\n",
    "First, retrieve the model via the function below.  \r\n",
    "Change the path according to your setup.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def retrieve_model(path):\r\n",
    "    trained_model = load(path)\r\n",
    "    return trained_model\r\n",
    "\r\n",
    "lgbr_cars = retrieve_model(\"lgbr_cars.model\")\r\n",
    "\r\n",
    "tc.assertEqual(str(type(lgbr_cars)),\"<class 'lightgbm.sklearn.LGBMRegressor'>\", type(lgbr_cars))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now you have your trained model, lets do a functional test based on the parameters below.  \r\n",
    "You have to present the parameters in this order.  \r\n",
    "\r\n",
    "* vehicleType: coupe\r\n",
    "* gearbox: manuell\r\n",
    "* powerPS: 190\r\n",
    "* model: NaN\r\n",
    "* kilometer: 125000\r\n",
    "* monthOfRegistration: 5 \r\n",
    "* fuelType: diesel\r\n",
    "* brand: audi\r\n",
    "\r\n",
    "Based on these parameters, you should get a predicted value of 14026.35068804\r\n",
    "However, the model doesnt accept string inputs, see the integer encoding below:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_test_input = [[3,1,190,-1,125000,5,3,1]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def make_prediction(trained_model, single_input):\r\n",
    "    predicted_value = trained_model.predict(single_input)\r\n",
    "    return predicted_value[0]\r\n",
    "\r\n",
    "predicted_value = make_prediction(lgbr_cars, model_test_input)\r\n",
    "\r\n",
    "tc.assertAlmostEqual(predicted_value, 14026.35, places=2)\r\n",
    "# just to make sure, we also assert our test data for the following excericise\r\n",
    "tc.assertAlmostEqual(make_prediction(lgbr_cars, [[-1,1,0,118,150000,0,1,38]]), 13920.70, places=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now you got this model up and running, we want you to **expose it as a rest api.**  \r\n",
    "We don't expect you to set up any authentication.  \r\n",
    "We're not looking for beautiful inputs, just make it work.  \r\n",
    "**Building this endpoint should NOT be done in a notebook, but in proper .py file(s)**\r\n",
    "\r\n",
    "Once its up and running, use it to predict the following input:\r\n",
    "* [-1,1,0,118,150000,0,1,38] ==> prediction should be 13920.70"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Geospatial data exercise\r\n",
    "The goal of this exercise is to read in some data from a shape file and visualize it on a map\r\n",
    "- The map should be dynamic. I want to zoom in and out to see more interesting aspects of the map\r\n",
    "- We want you to visualize the statistical sectors within a distance of 2KM of your home location.\r\n",
    "\r\n",
    "Specific steps to take:\r\n",
    "- Read in the shape file\r\n",
    "- Transform to WGS coordinates\r\n",
    "- Create a distance function (Haversine)\r\n",
    "- Create variables for home_lat, home_lon and perimeter_distance\r\n",
    "- Calculate centroid for each nis district\r\n",
    "- Calculate the distance to home for each nis district centroid \r\n",
    "- Figure out which nis districts are near your home\r\n",
    "- Create dynamic zoomable map\r\n",
    "- Visualize the nis districts near you (centroid <2km away), on the map\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Some imports to help you along the way\r\n",
    "import geopandas as gpd\r\n",
    "import folium # you can use any viz library you prefer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# part 1: Reading in the data\r\n",
    "# get this file from https://statbel.fgov.be/sites/default/files/files/opendata/Statistische%20sectoren/sh_statbel_statistical_sectors_20200101.shp.zip \r\n",
    "df = gpd.read_file('sh_statbel_statistical_sectors_20200101.shp')\r\n",
    "df = df.to_crs(\"EPSG:4326\") # change projection to wgs84 \r\n",
    "\r\n",
    "# One of the data scientists discovered stackoverflow ;-) and copypasted something from https://gis.stackexchange.com/questions/166820/geopandas-return-lat-and-long-of-a-centroid-point\r\n",
    "# A data science engineer should be able to speed this next code up\r\n",
    "df[\"lon\"] = df.geometry.centroid.x\r\n",
    "df[\"lat\"] = df.geometry.centroid.y"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Temp/ipykernel_17884/2146413365.py:8: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df[\"lon\"] = df.geometry.centroid.x\n",
      "C:\\Users\\kevin\\AppData\\Local\\Temp/ipykernel_17884/2146413365.py:9: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df[\"lat\"] = df.geometry.centroid.y\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Let's create some variables to indicate the location of your interest \r\n",
    "home = (51.101129, 4.369611)\r\n",
    "colruyt_HQ = (50.72953273040411, 4.222002043806561)\r\n",
    "perimeter_distance = 2 # km"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# ripped from https://stackoverflow.com/a/4913653\r\n",
    "def haversine(lon1, lat1, lon2, lat2):\r\n",
    "    \"\"\"\r\n",
    "    Calculate the great circle distance in kilometers between two points \r\n",
    "    on the earth (specified in decimal degrees)\r\n",
    "    \"\"\"\r\n",
    "    # convert decimal degrees to radians \r\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\r\n",
    "\r\n",
    "    # haversine formula \r\n",
    "    dlon = lon2 - lon1 \r\n",
    "    dlat = lat2 - lat1 \r\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\r\n",
    "    c = 2 * asin(sqrt(a)) \r\n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles. Determines return value units.\r\n",
    "    return c * r\r\n",
    "\r\n",
    "# https://stackoverflow.com/a/51431891\r\n",
    "def haversine_vectorized(lon1, lat1, lon2, lat2):\r\n",
    "    \"\"\"\r\n",
    "    Calculate the great circle distance between two points \r\n",
    "    on the earth (specified in decimal degrees)\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    #Convert decimal degrees to Radians:\r\n",
    "    lon1 = np.radians(lon1)\r\n",
    "    lat1 = np.radians(lat1)\r\n",
    "    lon2 = np.radians(lon2)\r\n",
    "    lat2 = np.radians(lat2)\r\n",
    "\r\n",
    "    #Implementing Haversine Formula: \r\n",
    "    dlon = np.subtract(lon2, lon1)\r\n",
    "    dlat = np.subtract(lat2, lat1)\r\n",
    "\r\n",
    "    a = np.add(np.power(np.sin(np.divide(dlat, 2)), 2),  \r\n",
    "                          np.multiply(np.cos(lat1), \r\n",
    "                                      np.multiply(np.cos(lat2), \r\n",
    "                                                  np.power(np.sin(np.divide(dlon, 2)), 2))))\r\n",
    "    c = np.multiply(2, np.arcsin(np.sqrt(a)))\r\n",
    "    r = 6371\r\n",
    "\r\n",
    "    return c*r"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, implement some sanity checks for your distance function "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# implement sanity checks here\r\n",
    "lyon = (45.7597, 4.8422)\r\n",
    "paris = (48.8567, 2.3508)\r\n",
    "expectedDistanceLyonParis = 392.2172595594006\r\n",
    "tc.assertEqual(haversine(0, 0, 0, 0), 0)\r\n",
    "tc.assertAlmostEqual(haversine(lyon[1], lyon[0], paris[1], paris[0]), expectedDistanceLyonParis, places=2)\r\n",
    "tc.assertAlmostEqual(haversine(paris[1], paris[0], lyon[1], lyon[0]), expectedDistanceLyonParis, places=2)\r\n",
    "tc.assertAlmostEqual(haversine(home[1], home[0], colruyt_HQ[1], colruyt_HQ[0]), 42.6, places=2)\r\n",
    "\r\n",
    "tc.assertEqual(haversine_vectorized(0, 0, 0, 0), 0)\r\n",
    "tc.assertAlmostEqual(haversine_vectorized(lyon[1], lyon[0], paris[1], paris[0]), expectedDistanceLyonParis, places=2)\r\n",
    "tc.assertAlmostEqual(haversine_vectorized(paris[1], paris[0], lyon[1], lyon[0]), expectedDistanceLyonParis, places=2)\r\n",
    "tc.assertAlmostEqual(haversine_vectorized(home[1], home[0], colruyt_HQ[1], colruyt_HQ[0]), 42.6, places=2)\r\n",
    "\r\n",
    "print(\"The distance from home to Colruyt HQ is\", round(haversine(home[1], home[0], colruyt_HQ[1], colruyt_HQ[0]), 2), \"km\")\r\n",
    "\r\n",
    "# benchmark both functions\r\n",
    "from time import perf_counter as time_perf_counter\r\n",
    "start_normal = time_perf_counter()\r\n",
    "_ = [haversine(home[1], home[0], lon, lat) for lon, lat in zip(df[\"lon\"], df[\"lat\"])]\r\n",
    "end_normal = start_vectorized = time_perf_counter()\r\n",
    "_ = haversine_vectorized(home[1], home[0], df[\"lon\"], df[\"lat\"])\r\n",
    "end_vectorized = time_perf_counter()\r\n",
    "print(\"havesine() for each row took:\", end_normal - start_normal)\r\n",
    "print(\"haversine_vectorized() took:\", end_vectorized - start_vectorized)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The distance from home to Colruyt HQ is 42.6 km\n",
      "havesine() for each row took: 0.028212400000029447\n",
      "haversine_vectorized() took: 0.0034871999999950276\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, create a dynamical map "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# implementation of the map goes here\r\n",
    "foliumMap = folium.Map(location=[home[0], home[1]], zoom_start=14)\r\n",
    "\r\n",
    "# Add home\r\n",
    "folium.Marker(location=[home[0], home[1]], popup=\"Home\", icon=folium.Icon(icon=\"home\", color=\"green\")).add_to(foliumMap)\r\n",
    "\r\n",
    "# Add Colruyt HQ\r\n",
    "folium.Marker(location=[colruyt_HQ[0], colruyt_HQ[1]], popup=\"ColruytHQ\", icon=folium.Icon(color=\"red\")).add_to(foliumMap)\r\n",
    "\r\n",
    "# Add all areas close to home\r\n",
    "def add_geometry_to_folium(geometry, lat, lon, popup):\r\n",
    "    sim_geo = gpd.GeoSeries(geometry)#.simplify(tolerance=0.001)\r\n",
    "    geo_j = sim_geo.to_json()\r\n",
    "    geo_j = folium.GeoJson(data=geo_j, style_function=lambda x: {'fillColor': 'blue'})\r\n",
    "    geo_j.add_to(foliumMap)\r\n",
    "\r\n",
    "    folium.Marker(location=[lat, lon], popup=popup).add_to(foliumMap)\r\n",
    "\r\n",
    "close_to_home = haversine_vectorized(home[1], home[0], df[\"lon\"], df[\"lat\"]) <= perimeter_distance\r\n",
    "_ = [add_geometry_to_folium(geometry, lat, lon, popup) for geometry, lat, lon, popup in df[close_to_home][[\"geometry\", \"lat\", \"lon\", \"T_SEC_NL\"]].to_numpy()]\r\n",
    "\r\n",
    "# Add all Colruyt supermarkets from df_clp\r\n",
    "for _, r in df_clp.iterrows():\r\n",
    "    folium.Marker(location=[r['geoCoordinates.latitude'], r['geoCoordinates.longitude']], icon=folium.Icon(color=\"orange\"), popup=r[\"commercialName\"]).add_to(foliumMap)\r\n",
    "\r\n",
    "foliumMap"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('.venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "17a51c22ee0d44991b45c50660ba115b0a8c796dbce19ba50e2a1eaaf19769c6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}